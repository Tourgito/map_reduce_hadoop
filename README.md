# Map Reduce using Hadoop

>> Team Project for the purposes of Big Data course,
>> University of Macedonia, Greece


Processing a dataset, which contains the personal data of the citizens of a city. The goal is to find the citizens, whose data exists more than once in the dataset and remove any duplicates. To accomplish the former, Apache Hadoop was used as well the technology Map Reduce. Furthermore, the same problem was solved a number of times, where in each the number of nodes of the Hadoop  cluster was different compared to the others executions. The time that was needed for each execution was written down and printed to a diagram to make comparisons, as well as various analytics.


# Members:

George Michoulis - dai16067 / 
Nikolaos Stefanidis - dai16054 / 
Dimitris Tourgaidis - dai16057 / 
Kwstas Tsiwlis - dai16060
